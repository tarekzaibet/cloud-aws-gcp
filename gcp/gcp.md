# Storage Products  

## Cloud Storage

### Buckets

- steps to create a bucket :
  - specify a globally unique name
  - choose a geographic location where your bucket and its content are stored
  - a default storage class : (The default storage class you choose applies to objects added to the bucket that don't have a storage class specified explicitly.)
- You can apply labels to a bucket (key:value). Each bucket has a maximum of 64 labels

### Objects

- There is no limit on the number of objects you can store in a bucket
- Objects has two components : object data & object metadata
- Object versioning : by default when you overwrite an object, Storage deletes the old version and replaces it with a new version, unless you enable object versioning. In this case when you delete an object, the object is identified with an older generation number, you can retrieve the version by its generation number.
- objects are immutable, objects cannot change throughout it's storage life time

### Geo-redundancy

- Geo-redundant data are stored in at least two separate geographic places separated by at least 100 miles.
- Objects stored in multi-regions and dual-regions are geo-redundant.  
- ensures HA of your data
- occurs asynchronously

### Storage Locations

- Use a region to help optimize latency and network bandwidth for data consumers, such as analytics pipelines, that are grouped in the same region.

- Use a dual-region when you want similar performance advantages as regions, but also want the higher availability that comes with being geo-redundant, A dual-region is a specific pair of regions, such as Finland and the Netherlands.

- Use a multi-region when you want to serve content to data consumers that are outside of the Google network and distributed across large geographic areas, or when you want the higher availability that comes with being geo-redundant.A multi-region is a large geographic area, such as the United States, that contains two or more geographic places.

- Objects stored in a multi-region or dual-region are geo-redundant.

### Storage Classes

- Standard storage :
  - best for short term objects and frequently accessed data
  - Minimum storage duration : None
  - SLA : >99.99% in multi-regions and dual-regions. 99.99% in regions
- Nearline storage :
  - best for backups and data accessed once a month or less
  - Minimum storage duration : 30 days
  - SLA : >99.95% in multi-regions and dual-regions. 99.9% in regions
- Coldline storage :
  - best for data recovery and data accessed once a year or less
  - Minimum storage duration : 90 days
  - SLA : >99.95% in multi-regions and dual-regions. 99.9% in regions

### Object Lifecyle Management

- you can set these conditions on an object :
    - age
    - createdbefore
    - matches storage class
    - number of newer versions

- you can set these actions on an object :
   - Delete
   - set storage class

- when you change a configuration, it takes place 24 hours later

### Object versioning

- You enable Object Versioning for a bucket. Once enabled, Cloud Storage creates an archived version of an object each time the live version of the object is overwritten or deleted. The archived version retains the name of the object but is uniquely identified by a generation number. While all objects have generation numbers associated with them, only archived objects require generation numbers in order to identify them.

### Encryption  

- Google managed encryption keys : Cloud Storage manages server-side encryption keys on your behalf using the same hardened key management systems that we use for our own encrypted data, including strict key access controls and auditing. Cloud Storage encrypts user data at rest using AES-256
- Customer supplied encryption keys : As an additional layer on top of Google-managed encryption keys, you can choose to provide your own AES-256 key, encoded in standard Base64.
- Customer managed encryption keys : As an additional layer on top of Google-managed encryption keys, you can choose to use keys generated by Cloud Key Management Service. Such keys are known as customer-managed encryption keys. If you use a customer-managed encryption key, your encryption keys are stored within Cloud KMS. The project that holds your encryption keys can then be independent from the project that contains your buckets, thus allowing for better separation of duties.
- Client side keys :When you perform client-side encryption, you must create and manage your own encryption keys, and you must use your own tools to encrypt data prior to sending it to Cloud Storage

## Cloud SQL

- fully managed relational database, you can choose mySQL, PostgreSQL and SQL server as db engine. Google handles replication, patch management and database management to ensure availability and performance.
- it's zonal (you specify a region than a zone)
- scaling is manual both horizontally and vertically.
- you can manually enable high availability : by changing the instance availabillty from single zone to high availabillty, the instance will automatically fail over to another zone in your selected region in case of an outage. High availabillty is recommended for production instances and increases your cost.
- you can create a clone of your db : separate, independent copy of a master instance and assists in point-in-time recovery, you can choose to clone the latest state of instance, or from earlier position (manually enter an earlier binary log position)

### Replication

- MySQL and PostgreSQL : Data replication between multiple zones with automatic failover with strong replica consistency
- SQL Server : not available

### Backups

- MySQL : automated and on demand backups
- PostgreSQL : automated and on demand backups
- SQL Server : automated and on demand backups


## Cloud Spanner

- regional, multi-regional (you choose a configuration where your nodes and data are located)
- mission critical, fully managed relational database service that offers transactional consistency at global scale, schemas, SQL, and automatic, asynchronous replication for HA
- uses SQL to query data
- can scale from one node to thousands of nodes
- can scale horizontally
- strongly consistent
- requires 3 nodes for a production environment

## Cloud Spanner vs Cloud SQL

- Spanner is horizontaly scalable whereas Cloud SQL is not, with cloud SQL you are limited with having everything on one server.
- for Cloud SQL maximal data throughput through network is 2000 MB/s
- With cloud spanner you can scale horizontaly by adding nodes, with every node throughput increases.
- Each node in Spanner has 10000 QPS for reads or 2000 QPS for writes and 2 TB of storage
- Spanner is more expensive
- Cloud SQL is for basic and generic SQL needs while Spanner is best used for massive scale opportunites
- better use cloud sql for not massive data, such as customer list
- they are both used for OLTP
- data distribution for cloud sql is zonal whereas it's regional or global for cloud spanner

## Cloud Firestore

- a cloud hosted no-sql database. You store data in documents, which contains fields mapping to values. Theses documents are stored in collections, which are simply containers that help you organize and query your documents.
- similar to dynamoDB
- Fully Managed noSQL db

## Bigtable

- fast, fully managed, massivly scalable noSQL database service. it's a wide column database.
- Regional
- Automatic storage scaling
- Manual processing nodes scaling
- when to use it ? :
  - storing >= 1 TB of structured data
  - when the volume of writes are very high
  - when strong consistency and highly performant read/right is required
- Integrates with : Hadoop, Dataflow, Dataproc

## Cloud Filestore

- managed file storage service for applications that require a filesystem interface and shared filesystem for data.
- use cloud filestore to create fully managed NFS file servers on GCP for use with applications running on Compute engine VM's or Google Kubernetes engine clusters.


## Cloud Memorystore

- Memorystore for redis, fully managed in memory data store service buit on scalable, secure and highly available infrastructure managed by google

# Compute Products

## App Engine

- fully managed
- takes care of provisioning servers and scaling your app instances based on demand
- has two environments : standard and flexible
- standard : Python, Java, Go, PHP
- flexible : Java 8, Servlet 3.1, Jetty 9, Node js, ruby, php, .net, go

## Compute Engine

- you choose a zone where to create a compute engine
- you have complete controle over : CPU/GPU, Memory, Disk Space, OS, Firewalls, Network connection/management

### storage in Compute Engine

- Local SSD : (epehemeral)
  - belongs to a zone
  - 375GB
  - if the instance shuts down the data is lost
  - pay for GB-month provisioned

- Persistent Disk
  - belongs to a zone
  - performance scales with volume size
  - can be resized while in use but will need file system update within the VM
  - snapshots are incremental

### instance groups

- you can create VM's via instance group so you don't create them individually
- you create VM's using instance template
- two types of instance groups : managed (zonal or regional ) and unmanaged
- managed :
  - use instance templates to create a group of identical ressources.
  - benefits of this are :
    - add load balancing to route traffic to instances in instance group
    - automatic scaling
    - if an instance crashes an automatic new one is created
  - zonal : instances in the same zone
  - regional : instances in the same region
- unmanaged :
  - dissimilar instances that you can arbitraily add and remove from the group
  - doesn't have auto-scaling, instance template, rolling update

## Google Kubernetes Engine

- managed environment for deploying, managing and scaling your containerized applications using google infrastructure.
- consists of multiple machines grouped together to form a cluster
- benefits of using GKE :
  - load balancing for compute engine instances
  - automatic scaling of your cluster's node instance count
  - automatic upgrades for your cluster's node software
  - node auto-repair
  - logging and monitoring with stackdriver
- GKE masters are automatically upgraded to run new versions of Kubernetes
- Production clusters require >= 3 nodes
- No IAM Integration : you have to manage the secrets manually
- Powered by kubernetes
- Managed applications not machines

# Big Data Products

## Composer

- Cloud Composer is a managed Apache Airflow (used to orchestrate your data pipelines) service that helps you create, schedule, monitor and manage workflows. Cloud Composer automation helps you create Airflow environments quickly and use Airflow-native tools, such as the Airflow web UI and command line tools, so you can focus on your workflows and not your infrastructure.
- to learn more about airflow : https://airflow.apache.org/concepts.html

## Dataproc

- Zonal
- Cloud Dataproc is a managed Apache Spark and Apache Hadoop service that lets you take advantage of open source data tools for batch processing, querying, streaming, and machine learning.
- Cloud Dataproc automation helps you create clusters quickly, manage them easily, and save money by turning clusters off when you don't need them. With less time and money spent on administration, you can focus on your jobs and your data.
- Scales by removing or adding nodes, even while jobs are running
- Integrates with :  GCS, BigTable, BigQuery, some stackdriver services
- pay for GCE servers used in the cluster

## Dataflow

- Zonal
- Fully managed service for transforming and enriching data in stream (real time) and batch (historical) modes with equal reliability and expressiveness. With its serverless approach to ressource provisioning and management, you have access to virtually limitless capcity to solve your biggest data processing challenges, while paying only for what you use.
- Managed service for executing a wide variety of data processing patterns. You can deploy batch or streaming data processing pipelines using Cloud Dataflow.
- You create your pipelines with Apache Beam program and then run them on the Cloud Dataflow service.
- Integratew with : Pub/Sub, Datastore, BigQuery, BigTable, Cloud ML, Stackdriver
- to learn more about apache beam : https://beam.apache.org/documentation/pipelines/design-your-pipeline/

## BigQuery

- data warehouse
- designed to make data analysis more productive
- no infrastructure to manage (noOPS)
- use SQL to query data

## Pub/Sub

- Global
- fully managed
- send and receive message between independent applications.
- Pay for data volume
- Messages :
    - Can be up to 10 MB
    - Undelivered messages are stored for 7 days
    - There is no Dead Letter Queue (DLQ)
- Modes :
    - Push : Delivers to HTTP endpoints
    - Pull : Delivers messages to requesting clients and awaits for ACK to delete or until timer expires
    - lets client set rate of consumption, and supports batching and long-polling

# Development Products

## Cloud Build

- service that executes your builds on Google Cloud Platform's infrastructure.
- can import source code from a variety of repos (Google source repo, github, bitbucket)
- produce artifacts such as a docker containers or java archives
- you can use the supported build steps or write your own build steps
- each build step is run in a docker container

## Cloud Deployment Manager

- allows you to specify all the ressources needed for your application in a declarative format using yaml.
- you can also use python or jinja2 templates to parameterize the configuration and allow reuse of common deployment paradigms such as a load balancer, auto-scaled instance group.
- allows you to have repeatable deployment configuration in one file

## Cloud Tasks

- fully managed service
- allows you to manage the execution, dispatch and delivery of a large number of distributed tasks.
- you can asynchronously perform work outside of a user request
- your tasks can be executed on App Engine or any arbitrary HTTP endpoint

## Identity platform

- Identity Platform provides back-end services, SDKs, and UI libraries that make authenticating users to your applications and services easy.

## Cloud Endpoints

- Global
- Pay per call to your API
- Handles Auth, monitoring, logging and API keys for APIs backed by GCP
- Integrates with : Firebase, Auth0, Google Auth

## Cloud Source Repository

- Cloud Source Repositories are fully featured, private Git repositories hosted on Google Cloud Platform.
